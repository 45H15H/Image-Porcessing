{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HandDetector(maxHands=1, detectionCon=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "# frame_size = (int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = cv2.VideoWriter('output.mp4', fourcc, fps, frame_size, isColor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the frames from the video capture\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "   \n",
    "\n",
    "    # perform hand detection\n",
    "    hands, img = detector.findHands(frame)\n",
    "\n",
    "    # cv2.rectangle() has the following parameters:\n",
    "    # cv2.rectangle(img, start_point, end_point, color, thickness)\n",
    "    # color is in BGR format\n",
    "\n",
    "    cv2.rectangle(img, (0, 480), (300, 425), (255, 50, 50), -2)\n",
    "    cv2.rectangle(img, (640, 480), (400, 425), (50, 50, 255), -2)\n",
    "        \n",
    "    if hands: # if there is a hand in the image\n",
    "        # Hand 1\n",
    "        hand = hands[0]\n",
    "        lmList1 = hand[\"lmList\"]  \n",
    "        bbox1 = hand[\"bbox\"]  \n",
    "        centerPoint1 = hand['center']  \n",
    "        handType1 = hand[\"type\"]\n",
    "\n",
    "        fingers = detector.fingersUp(hand)\n",
    "\n",
    "        # if right hand is in the image with all the fingers up\n",
    "        if fingers == [0, 0, 0, 0, 1]:\n",
    "            cv2.putText(frame, 'Right Direction', (20, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Right', (420, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            # press right\n",
    "            pyautogui.press('right')\n",
    "        elif fingers == [0, 1, 0, 0, 0]:\n",
    "            cv2.putText(frame, 'Left Direction', (20, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Left', (420, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            # press left\n",
    "            pyautogui.press('left')\n",
    "        elif fingers == [0, 1, 1, 1, 1]:\n",
    "            cv2.putText(frame, 'Up Direction', (20, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Up', (420, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            # press up\n",
    "            pyautogui.press('up')\n",
    "        elif fingers == [1, 0, 0, 0, 0]:\n",
    "            cv2.putText(frame, 'Down Direction', (20, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Down', (420, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            # press down\n",
    "            pyautogui.press('down')\n",
    "        elif fingers == [0, 0, 0, 0, 0]:\n",
    "            cv2.putText(frame, 'Nothing', (20, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'No Action', (420, 460), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # write the frame to the output file\n",
    "    # out.write(img)\n",
    "\n",
    "    # show the processed frame \n",
    "    cv2.imshow('frame', img)\n",
    "    # press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture and video writer objects\n",
    "video_capture.release()\n",
    "# out.release()\n",
    "\n",
    "# close all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "debc2121511f37620e4e406b8e25acf7be96315b8b48c387eff272a1baf02ae1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
