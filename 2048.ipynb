{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be developing a simple game that is controlled by hand gestures. The game will detect the position of the player's hand in the video frame and use that information to control the direction of the game character."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start, make sure to have the following packages installed:\n",
    "* OpenCV\n",
    "* cvzone\n",
    "* PyAutoGUI\n",
    "\n",
    "Install these packages using the following commands:\n",
    "* `pip3 install opencv-python`\n",
    "* `pip3 install cvzone`\n",
    "* `pip3 install pyautogui`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "Import these libraries for use in the project:\n",
    "\n",
    "1. `HandDetector` from `cvzone.HandTrackingModule`: This library is responsible for detecting and tracking hand gestures.\n",
    "\n",
    "2. `cv2` (OpenCV): This library is a computer vision library that is used for image and video processing.\n",
    "\n",
    "3. `pyautogui`: This library provides an interface for automating GUI interactions and is used for controlling the mouse and keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2\n",
    "import pyautogui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Hand Detector\n",
    "\n",
    "The following cell creates an instance of the `HandDetector` class and assigns it to the variable `detector`. \n",
    "\n",
    "The two arguments passed to the class constructor are:\n",
    "\n",
    "1. `maxHands`: This argument specifies the maximum number of hands that the detector should be able to track. In our case, `maxHands` is set to 1, which means that the detector will only track one hand at a time.\n",
    "\n",
    "2. `detectionConfidence`: This argument sets the minimum confidence level for hand detection. In our case, the `detectionConfidence` is set to 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HandDetector(maxHands=1, detectionCon=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Video Input\n",
    "\n",
    "The following cell creates a `VideoCapture` object and assigns it to the variable `video_capture`. The `VideoCapture` class is part of the OpenCV library and is used to capture video from the camera.\n",
    "\n",
    "The argument passed to the `VideoCapture` constructor, `0`, is the index of the camera that will be used for video capture. In our case, `0` specifies the default camera on the computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop\n",
    "\n",
    "The following cell is for hand gesture detection and control using computer vision and PyAutoGUI library. The script reads frames from a video source and performs hand detection using the `detector.findHands` function. The script then uses the detected hand information to perform actions based on hand gestures. The actions are executed using PyAutoGUI's `pyautogui.press` function. \n",
    "\n",
    "The `cv2.rectangle` function is used to draw rectangles on the processed frame for visual representation. The rectangles are used to indicate the direction of the hand gesture.\n",
    "\n",
    "The script uses a while loop to continuously read frames from the video source. Within the loop, the `fingersUp` function is used to determine the number of fingers that are up. Depending on the number of fingers, the script performs different actions and displays text on the processed frame indicating the direction of the hand gesture.\n",
    "\n",
    "The processed frame is displayed using the `cv2.imshow` function, and the script waits for the user to press 'q' to exit. Upon exit, the script releases the video capture and closes all frames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while loop to continuously detect hands\n",
    "# move to mouse to (467, 696) before starting the loop \n",
    "pyautogui.moveTo(467, 696)\n",
    "pyautogui.click()\n",
    "\n",
    "screenWidth, screenHeight = (856, 387)\n",
    "# screenWidth, screenHeight = (856, 250)\n",
    "\n",
    "while True:\n",
    "    # read the video capture\n",
    "    ret, frame = video_capture.read()\n",
    "   \n",
    "    # perform hand detection\n",
    "    hands, img = detector.findHands(frame)\n",
    "\n",
    "    # draw the rectangle on the screen\n",
    "    cv2.rectangle(img, (0, 480), (300, 425), (255, 50, 50), -2) # left rectangle, blue color\n",
    "    cv2.rectangle(img, (640, 480), (400, 425), (50, 50, 255), -2) # right rectangle, red color\n",
    "    \n",
    "    # if there is a hand in the image\n",
    "    if hands: \n",
    "        # get the first hand\n",
    "        hand = hands[0]\n",
    "        # get the landmarks of the hand\n",
    "        lmList = hand[\"lmList\"]\n",
    "        # get the bounding box of the hand\n",
    "        bbox = hand[\"bbox\"]\n",
    "        # get the center of the hand\n",
    "        centerPoint = hand['center'] \n",
    "        # get the type of the hand \n",
    "        handType = hand[\"type\"]\n",
    "        # get the fingers up\n",
    "        fingers = detector.fingersUp(hand)\n",
    "\n",
    "        \n",
    "        # if palm is visible\n",
    "        if fingers == [1, 1, 1, 1, 1]:\n",
    "    \n",
    "            # if lmList[9][0] < 150:\n",
    "            #     # press left\n",
    "            #     pyautogui.press('left')\n",
    "            # if lmList[9][0] > 1750:\n",
    "            #     # press right\n",
    "            #     pyautogui.press('right')\n",
    "            # if lmList[9][1] < 200:\n",
    "            #     # press up\n",
    "            #     pyautogui.press('up')\n",
    "            # if lmList[9][1] > 500:\n",
    "            #     # press down\n",
    "            #     pyautogui.press('down')\n",
    "\n",
    "            \n",
    "            if lmList[9][0] < 450 and lmList[9][1] > 220 and lmList[9][1] < 500:\n",
    "                # press left\n",
    "                pyautogui.press('left')\n",
    "            elif lmList[9][0] > 450 and lmList[9][1] < 220 and lmList[9][1] > 00 and lmList[9][0] < 830:\n",
    "                # press up\n",
    "                pyautogui.press('up')\n",
    "            elif lmList[9][0] > 830 and lmList[9][1] < 500 and lmList[9][1] > 200 and lmList[9][0] < 1280:\n",
    "                # press right\n",
    "                pyautogui.press('right')\n",
    "            elif lmList[9][0] > 450 and lmList[9][1] > 500 and lmList[9][1] < 720 and lmList[9][0] < 830:\n",
    "                # press down\n",
    "                pyautogui.press('down')\n",
    "                \n",
    "    # show the processed frame \n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    # press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture\n",
    "video_capture.release()\n",
    "\n",
    "# close all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Make sure you have the game window open and focused when running the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailSafeException",
     "evalue": "PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailSafeException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\ImageProcessing\\OPENCV\\2048.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ImageProcessing/OPENCV/2048.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pyautogui\u001b[39m.\u001b[39mpress(\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ImageProcessing/OPENCV/2048.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ImageProcessing/OPENCV/2048.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pyautogui\u001b[39m.\u001b[39;49mpress(\u001b[39m'\u001b[39;49m\u001b[39mdown\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ImageProcessing/OPENCV/2048.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.2\u001b[39m)\n",
      "File \u001b[1;32md:\\ImageProcessing\\lib\\site-packages\\pyautogui\\__init__.py:597\u001b[0m, in \u001b[0;36m_genericPyAutoGUIChecks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(wrappedFunction)\n\u001b[0;32m    596\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 597\u001b[0m     failSafeCheck()\n\u001b[0;32m    598\u001b[0m     returnVal \u001b[39m=\u001b[39m wrappedFunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    599\u001b[0m     _handlePause(kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_pause\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[1;32md:\\ImageProcessing\\lib\\site-packages\\pyautogui\\__init__.py:1722\u001b[0m, in \u001b[0;36mfailSafeCheck\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1720\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfailSafeCheck\u001b[39m():\n\u001b[0;32m   1721\u001b[0m     \u001b[39mif\u001b[39;00m FAILSAFE \u001b[39mand\u001b[39;00m \u001b[39mtuple\u001b[39m(position()) \u001b[39min\u001b[39;00m FAILSAFE_POINTS:\n\u001b[1;32m-> 1722\u001b[0m         \u001b[39mraise\u001b[39;00m FailSafeException(\n\u001b[0;32m   1723\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1724\u001b[0m         )\n",
      "\u001b[1;31mFailSafeException\u001b[0m: PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED."
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(2)\n",
    "while True:\n",
    "    pyautogui.press('left')\n",
    "    time.sleep(0.2)\n",
    "    pyautogui.press('up')\n",
    "    time.sleep(0.2)\n",
    "    pyautogui.press('right')\n",
    "    time.sleep(0.2)\n",
    "    pyautogui.press('down')\n",
    "    time.sleep(0.2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "debc2121511f37620e4e406b8e25acf7be96315b8b48c387eff272a1baf02ae1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
