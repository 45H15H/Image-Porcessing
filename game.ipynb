{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be developing a simple game that is controlled by hand gestures. The game will detect the position of the player's hand in the video frame and use that information to control the direction of the game character."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start, make sure to have the following packages installed:\n",
    "* OpenCV\n",
    "* cvzone\n",
    "* PyAutoGUI\n",
    "\n",
    "Install these packages using the following commands:\n",
    "* `pip3 install opencv-python`\n",
    "* `pip3 install cvzone`\n",
    "* `pip3 install pyautogui`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "Import these libraries for use in the project:\n",
    "\n",
    "1. `HandDetector` from `cvzone.HandTrackingModule`: This library is responsible for detecting and tracking hand gestures.\n",
    "\n",
    "2. `cv2` (OpenCV): This library is a computer vision library that is used for image and video processing.\n",
    "\n",
    "3. `pyautogui`: This library provides an interface for automating GUI interactions and is used for controlling the mouse and keyboard."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Hand Detector\n",
    "\n",
    "The following cell creates an instance of the `HandDetector` class and assigns it to the variable `detector`. \n",
    "\n",
    "The two arguments passed to the class constructor are:\n",
    "\n",
    "1. `maxHands`: This argument specifies the maximum number of hands that the detector should be able to track. In our case, `maxHands` is set to 1, which means that the detector will only track one hand at a time.\n",
    "\n",
    "2. `detectionConfidence`: This argument sets the minimum confidence level for hand detection. In our case, the `detectionConfidence` is set to 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = HandDetector(maxHands=1, detectionCon=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Video Input\n",
    "\n",
    "The following cell creates a `VideoCapture` object and assigns it to the variable `video_capture`. The `VideoCapture` class is part of the OpenCV library and is used to capture video from the camera.\n",
    "\n",
    "The argument passed to the `VideoCapture` constructor, `0`, is the index of the camera that will be used for video capture. In our case, `0` specifies the default camera on the computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop\n",
    "\n",
    "The following cell is for hand gesture detection and control using computer vision and PyAutoGUI library. The script reads frames from a video source and performs hand detection using the `detector.findHands` function. The script then uses the detected hand information to perform actions based on hand gestures. The actions are executed using PyAutoGUI's `pyautogui.press` function. \n",
    "\n",
    "The `cv2.rectangle` function is used to draw rectangles on the processed frame for visual representation. The rectangles are used to indicate the direction of the hand gesture.\n",
    "\n",
    "The script uses a while loop to continuously read frames from the video source. Within the loop, the `fingersUp` function is used to determine the number of fingers that are up. Depending on the number of fingers, the script performs different actions and displays text on the processed frame indicating the direction of the hand gesture.\n",
    "\n",
    "The processed frame is displayed using the `cv2.imshow` function, and the script waits for the user to press 'q' to exit. Upon exit, the script releases the video capture and closes all frames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left clicked\n",
      "Up clicked\n",
      "Right clicked\n",
      "Up clicked\n",
      "Down clicked\n",
      "Left clicked\n",
      "Up clicked\n",
      "Right clicked\n",
      "Down clicked\n",
      "Down clicked\n",
      "Left clicked\n",
      "Up clicked\n",
      "Right clicked\n",
      "Down clicked\n",
      "Left clicked\n",
      "Up clicked\n",
      "Right clicked\n",
      "Down clicked\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    " \n",
    "\n",
    "points_left = np.array([[0, 0], [450, 220], [450, 500], [0, 720]])\n",
    "points_top = np.array([[0, 0], [450, 220], [830, 220], [1280, 0]])\n",
    "points_right = np.array([[1280, 0], [830, 220], [830, 500], [1280, 720]])\n",
    "points_down = np.array([[1280, 720], [830, 500], [450, 500], [0, 720]])\n",
    "\n",
    "\n",
    "count = 1\n",
    "frame_counter = 0\n",
    "frame_counter_clicked = 0\n",
    "flag = False\n",
    "\n",
    "curr = \"NULL\"\n",
    "\n",
    "while True:\n",
    "    # Get image frame\n",
    "\n",
    "    left_flag = False\n",
    "    right_flag = False\n",
    "    top_flag = False\n",
    "    down_flag = False\n",
    "\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    copiedImage = img.copy()\n",
    "    another_copiedImage = copiedImage.copy()\n",
    "    copiedImage = cv2.rectangle(copiedImage, (450, 220), (830, 500), (102, 0, 204), 3)\n",
    "    copiedImage = cv2.line(copiedImage, (0, 0), (450, 220), (102, 0, 204), 3)\n",
    "    copiedImage = cv2.line(copiedImage, (830, 220), (1280, 0), (102, 0, 204), 3)\n",
    "    copiedImage = cv2.line(copiedImage, (0, 720), (450, 500), (102, 0, 204), 3)\n",
    "    copiedImage = cv2.line(copiedImage, (830, 500), (1280, 720), (102, 0, 204), 3)\n",
    "    img = cv2.putText(img, '2048 using Hand Gesture Control ', (180, 70), cv2.FONT_HERSHEY_TRIPLEX ,\n",
    "                        1.3, (102, 0, 204), 3, cv2.LINE_AA)\n",
    "\n",
    "    ret, gif_image = cap_gif.read()\n",
    "    frame_counter += 1\n",
    "    frame_counter_clicked += 1\n",
    "\n",
    "    if frame_counter == cap_gif.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        frame_counter = 0  # Or whatever as long as it is the same as next line\n",
    "        cap_gif.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    gif_image = cv2.resize(gif_image, (400, 200), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "\n",
    "    # Find the hand and its landmarks\n",
    "    hands, img = detector.findHands(img)  # with draw\n",
    "    hands2, copiedImage = detector.findHands(copiedImage)  # with draw\n",
    "\n",
    "    if hands and hands2:\n",
    "        # Hand 1\n",
    "        hand1 = hands[0]\n",
    "        lmList1 = hand1[\"lmList\"]  # List of 21 Landmark points\n",
    "        bbox1 = hand1[\"bbox\"]  # Bounding box info x,y,w,h\n",
    "        centerPoint1 = hand1['center']  # center of the hand cx,cy\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "        if fingers1 == [1, 1, 1, 0, 0]:\n",
    "            if lmList1[12][0] > 800 and lmList1[12][0] < 1200 and lmList1[12][1] > 150 and lmList1[12][1] < 350 and not flag:\n",
    "                flag = True\n",
    "                pyautogui.press('space')\n",
    "        if fingers1 == [1, 1, 1, 1, 1]:\n",
    "            if lmList1[9][0] < 450 and lmList1[9][1] > 220 and lmList1[9][1] < 500:\n",
    "                left_flag = True\n",
    "            elif lmList1[9][0] > 450 and lmList1[9][1] < 220 and lmList1[9][1] > 00 and lmList1[9][0] < 830:\n",
    "                top_flag = True\n",
    "            elif lmList1[9][0] > 830 and lmList1[9][1] < 500 and lmList1[9][1] > 200 and lmList1[9][0] < 1280:\n",
    "                right_flag = True\n",
    "            elif lmList1[9][0] > 450 and lmList1[9][1] > 500 and lmList1[9][1] < 720 and lmList1[9][0] < 830:\n",
    "                down_flag = True\n",
    "    # # Display\n",
    "    if not flag:\n",
    "        img[150:350, 800:1200] = gif_image\n",
    "        cv2.imshow(\"Image\", img)\n",
    "    else:\n",
    "        colorGlow = (39, 243, 141)\n",
    "        if left_flag:\n",
    "            cv2.fillPoly(copiedImage, pts=[points_left], color=colorGlow)\n",
    "            copiedImage = cv2.addWeighted(copiedImage, 0.7, another_copiedImage, 0.3, 0)\n",
    "            if curr != \"left\":\n",
    "                pyautogui.press(\"left\")\n",
    "                curr = \"left\"\n",
    "                print(\"Left clicked\")\n",
    "\n",
    "        elif right_flag:\n",
    "            cv2.fillPoly(copiedImage, pts=[points_right], color=colorGlow)\n",
    "            copiedImage = cv2.addWeighted(copiedImage, 0.7, another_copiedImage, 0.3, 0)\n",
    "            if curr != \"right\":\n",
    "                pyautogui.press(\"right\")\n",
    "                curr = \"right\"\n",
    "                print(\"Right clicked\")\n",
    "            # pyautogui.press(\"right\")\n",
    "        elif top_flag:\n",
    "            cv2.fillPoly(copiedImage, pts=[points_top], color=colorGlow)\n",
    "            copiedImage = cv2.addWeighted(copiedImage, 0.7, another_copiedImage, 0.3, 0)\n",
    "            if curr != \"top\":\n",
    "                pyautogui.press(\"up\")\n",
    "                curr = \"top\"\n",
    "                print(\"Up clicked\")\n",
    "            # pyautogui.press(\"up\")\n",
    "        elif down_flag:\n",
    "\n",
    "            cv2.fillPoly(copiedImage, pts=[points_down], color=colorGlow)\n",
    "            copiedImage = cv2.addWeighted(copiedImage, 0.7, another_copiedImage, 0.3, 0)\n",
    "            if curr != \"down\":\n",
    "                pyautogui.press(\"down\")\n",
    "                curr = \"down\"\n",
    "                print(\"Down clicked\")\n",
    "        else:\n",
    "            curr = \"NULL\"\n",
    "        image = cv2.putText(copiedImage, 'Up', (630, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1, (102, 0, 204), 2, cv2.LINE_AA)\n",
    "        image = cv2.putText(copiedImage, 'Left', (10, 350), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1, (102, 0, 204), 2, cv2.LINE_AA)\n",
    "        image = cv2.putText(copiedImage, 'Right', (1190, 330), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1, (102, 0, 204), 2, cv2.LINE_AA)\n",
    "        image = cv2.putText(copiedImage, 'Down', (630, 700), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            1, (102, 0, 204), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Image\", copiedImage)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cap_gif.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "debc2121511f37620e4e406b8e25acf7be96315b8b48c387eff272a1baf02ae1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
